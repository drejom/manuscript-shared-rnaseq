<!--
1. Library dependencies:
- knitcitations
- tools
- hpgltools

2. Shared manuscript code dependencies:
- count_tables.R

3. CONFIG dependencies
- include_tables
- samples
- condition
- batch
- covariates
- sample_id
- use_cache
- input_count_tables
-->

Load RNA-Seq counts
-------------------

### Samples

```{r sample_overview, results='asis'}
# Samples included in this analysis
if (CONFIG$include_tables) {
  kable(head(CONFIG$samples[, 1:min(6, ncol(CONFIG$samples))], 50), 
        caption='RNA-Seq samples.')
}
```

### Load sample information

To make things easier, all of the relevant experiment sample information
including sample ID, condition, and batch have been stored in separate CSV
files.

During the processing of the analysis configuration above, the relevant
sample metadata was loaded. Here we create a few variables containing different
subsets of this information that will be useful throughout the downstream
analyses.

During the differential expression analysis, we will use a larger subset of the
samples in order to improve our estimation of variance and batch effects.

```{r prep_metadata}
# Sample metadata
sample_ids <- as.character(CONFIG$samples[[CONFIG$sample_id]])
condition  <- factor(CONFIG$samples[[CONFIG$condition]])
batch      <- factor(CONFIG$samples[[CONFIG$batch]])

# Covariate dataframe
covariates <- CONFIG$samples %>% 
  select(!!CONFIG$covariates)

# Make sure levels for batch and condition are valid
#levels(condition) <- make.names(levels(condition))
#levels(batch) <- make.names(levels(batch))

# Design matrix; this may be updated later if batch adjustment is enabled
design_condition_only  <- model.matrix(~0+condition)

if (length(levels(batch)) > 1) {
    design_including_batch <- model.matrix(~0+condition+batch)
}
```

### Load count tables

Next, we will use HPGLTools `#r citep(citation('hpgltools'))` to load in the count
data for each sample. Throughout our analyses we will apply several different
types of filters and data transformations.  Since the exact types of
normalization and filtering procedures we will want to apply may differ,
depending on the type of analysis we are interested in (e.g.  differential
expression vs. co-expression network analysis), for each type of analysis, we
will maintain a list with the count tables at each of the major steps in
processing. Whenever genes or samples are removed from one version of the count
table for that analysis, the same genes and samples will be removed from all
other versions of the count table. This way we can ensure that the dimensions
of the count matrix is consistent across all levels of processing, within a
given analysis.

The different stages of processing which will be maintained are:

- **raw**: Unmodified count values as generated by HT-Seq, or another
   quantification tool.
- **log2cpm**: Log2 and counts-per-million (CPM) transformed.
- **normed**: Counts with zero or more of the follow transformations: log2,
  CPM, Voom, quantile normalization
- **batch_adjusted**: Same as above, but with an (optional) batch adjustment
  step. If "batch_adjust" is set to "none", this will be the same as the
  `normed` version of the counts.
- **final**: The final version of the counts after all filtering and
  transformation steps have been applied.

Finally, note that while all of the lists of count tables will include the same
raw and log2cpm transformed count matrices, everything for "normed" onwards
will depend on the exact parameters of the analysis, as specified in the
settings.

```{r prepare_count_matrix,  results='asis', cache=CONFIG$use_cache, cache.lazy=FALSE, autodep=TRUE}
message("Preparing count matrix")

# Use pre-loaded count table
if (is.data.frame(CONFIG$input_count_tables)) {
  count_table <- CONFIG$input_count_tables
} else if (length(CONFIG$input_count_tables) == 1 && tolower(file_ext(CONFIG$input_count_tables)) %in% c('rda', 'rdata')) {
  # Load from RData
    # Check to see if count table has been loaded, and if not, load
    if (!CONFIG$input_count_var %in% ls()) {
      load(CONFIG$input_count_tables)
    }

    # assign to variable "dat"
    dat <- get(CONFIG$input_count_var)

    # ExpressionSet
    if (class(dat) == 'ExpressionSet') {
        count_table <- exprs(dat)
        attributes(count_table)$names <- NULL
    } else if (class(dat) == 'RangedSummarizedExperiment') {
        # RangedSummarizedExperiment
        count_table <- SummarizedExperiment::assays(dat)$counts
    }
} else  {
    # Find all matching count files
    count_files <- Sys.glob(CONFIG$input_count_tables)

    # Single combined count file
    if (length(count_files) == 1) {
        # Load combined count table
        # TODO: Generalize so that counts stored in arbitrary formats can be loaded
        count_table <- read.table(CONFIG$input_count_tables, header=TRUE,
                                  row.names=1, check.names=FALSE)
        count_table$gene_name <- NULL
    } 
}

# Remove ENSEMBL gene id version, if present
# e.g. "ENSG00000005421.8" -> "ENSG00000005421"
if (startsWith(rownames(count_table)[1], 'ENS')) {
    rownames(count_table) <- sub('\\.[0-9]*', '', rownames(count_table))
}

# Exclude any missing samples
#sample_ids <- sample_ids[sample_ids %in% colnames(count_table)]

# Filter out samples not needed for this analysis
count_table <- count_table[, sample_ids]

# Drop any rows with NA's (should only occur when comparing counts across
# experiments where different reference GFF's were used)
count_table <- count_table[complete.cases(count_table),]

# print initial size of raw count table
if (CONFIG$verbose) {
    cat(sprintf("**Count table dimensions:**\n"))
    cat(sprintf("- Rows: %d\n", nrow(count_table)))
    cat(sprintf("- Columns: %d\n", ncol(count_table)))
}
```

```{r include=CONFIG$debug, eval=CONFIG$debug}
sum(count_table)
```

Sample Overview
---------------

### Library sizes

```{r libsizes, include=CONFIG$include_plots, eval=CONFIG$include_plots, warning=FALSE}
# color scheme for plots
num_conditions <- length(unique(condition))

pal <- colorRampPalette(RColorBrewer::brewer.pal(num_conditions, 'Dark2'))(num_conditions)
colors <- pal[as.numeric(condition)]

# for smaller number of samples, use a bar plot
if (ncol(count_table) <= 20) {
  #plot_libsize(count_table, condition, colors=colors, scale=FALSE)
} else {
  # for larger numbers of samples, use a densit plots instead
  dat <- data.frame(size = apply(count_table, 2, sum), condition)

  ggplot(dat, aes(x = size, group = condition, color = condition)) +
    geom_density() +
    xlab("Library size") +
    ggtitle("Distribution of sample library sizes") +
    theme_bw() +
    theme(legend.position='none')
}
```

### Outlier check

Sample median pairwise Pearson correlation for raw counts.

```{r outlier_check, include=CONFIG$include_plots, eval=CONFIG$include_plots}
# TODO 2019/01/15 Fix / port to EDA
# plot_sample_correlations(count_table, condition, batch, mar=c(16,6,4,6))
```

